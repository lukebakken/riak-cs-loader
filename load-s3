#!/usr/bin/env bash

source ./lib/common.bash
check_s3cmd
set -o nounset

errfile=''
make_temp_file errfile
exec 3> $errfile

myfifodir=''
make_temp_dir myfifodir

loadfifo="${bname}.fifo"
rm -f "$loadfifo"
mkfifo -m 0700 "$loadfifo"
exec 5<> "$loadfifo" # hook pipe up to descriptor 5

function on_exit
{
  exec 3>&-
  exec 4>&-
  exec 5>&-

  rm -f "$loadfifo"
  rm -rf "$myfifodir"
  if [[ -s "$errfile" ]]
  then
    mv -f "$errfile" load-s3.err
  else
    rm -f "$errfile"
  fi
}
trap on_exit EXIT

data_dir='./load-s3-data'
if [[ ! -d $data_dir ]]
then
  mkdir $data_dir
fi
cache_dir='./load-s3-cache'
if [[ ! -d $cache_dir ]]
then
  mkdir $cache_dir
fi

start_time=$(date '+%Y-%m-%d_%H-%M-%S')
upload_log="$data_dir/${start_time}.log"

myfifo="$myfifodir/${bname}.fifo"
mkfifo -m 0700 "$myfifo"
exec 4<> "$myfifo" # hook pipe up to descriptor 4 for read/write

declare -i maximum=16 # max subprocesses at a time
declare -i running=0 # current running count

declare -i file_count=0
declare -i total_size=0
declare -i total_size_max=$(( 1024 * 1024 * 1024 * 1024 )) # 1TiB

pinfo "total_size_max $total_size_max"

rm -vf $cache_dir/*

declare -a upload_files
declare -i bs=$((1024*1024))
declare -i i=0
for i in {0..9}
do
  declare -i count=$((2**$i))
  pinfo "creating upload file. bs $bs count $count"
  dd if=/dev/urandom bs=$bs count=$count 2>/dev/null | openssl enc -a > $cache_dir/$i.txt
  upload_files[$i]=$(($bs * $count)) # NB: capture the size
done

./s3cmd/s3cmd -c .s3cfg mb s3://test-bucket

while (( total_size < total_size_max ))
do
  while (( running >= maximum ))
  do
    declare -i cpid=0
    declare -i size=0
    if IFS='|' read -u 4 cpid size
    then
      (( total_size += size ))
      wait $cpid
      (( --running ))
    fi
  done

  if (( file_count % 128 == 0 ))
  then
    pinfo "uploaded $file_count files, $total_size bytes"
  fi

  (
    declare -i tmpidx=$((file_count % 10)) # modulus must be one greater than file cache count
    tmpfile="$cache_dir/${tmpidx}.txt"
    declare -i size=${upload_files[$tmpidx]}

    s3cmd_output=''
    if [[ ! -s "$tmpfile" ]]
    then
      perr "zero-byte upload file: $tmpfile"
      rm -f "$tmpfile"
    else
      make_temp_file s3cmd_output

      s3_file="s3://test-bucket/file-${file_count}.txt"
      ./s3cmd/s3cmd -c .s3cfg put "$tmpfile" "$s3_file" > "$s3cmd_output" 2>&1
      if [[ $? == 0 ]]
      then
        echo "$s3_file|$size" >> "$upload_log"
      else
        cat >&3 <<EOT
------------------------------------------------------------------------ 
ERROR $? in s3cmd -c .s3cfg put "$tmpfile" "$s3_file"
EOT
      cat < "$s3cmd_output" >&3
      cat >&3 <<EOT
------------------------------------------------------------------------ 
EOT
      fi
    fi
    # TODO rm -f "$tmpfile" "$s3cmd_output"
    rm -f "$s3cmd_output"
    echo "$s3_file" 1>&5
    echo "$BASHPID|$size" 1>&4
  ) &

  (( ++running ))
  (( ++file_count ))

done

pinfo 'waiting for all subprocesses...'
while (( running > 0 ))
do
  declare -i cpid=0
  declare -i size=0
  if IFS='|' read -u 4 cpid size
  then
    (( total_size += size ))
    wait $cpid
    (( --running ))
  fi
done

echo "$total_size" > "${upload_log}.total"
pinfo "done: uploaded $file_count files, $total_size bytes"

exit 0

